# ğŸ§  LocalMind â€“ Your Local AI Assistant

A full-stack **self-hosted AI assistant** built with **Next.js**, **Tailwind CSS**, and **Ollama** (running locally).  
Supports **multiple AI models**, **chat history**, **authentication**, and **local MongoDB storage** for maximum privacy.

---

## ğŸ’¡ Why I Built This

Most AI chat platforms:

- Store your conversations in the cloud
- Require monthly payments
- Restrict which models you can use

I wanted a **private, secure, and cost-free alternative** that I control completely.

With **LocalMind**:

- ğŸ”’ **Full Privacy** â€“ All chats & history are stored locally on **my own device**, not on someone elseâ€™s servers.
- ğŸ§  **Model Freedom** â€“ Download & switch between different local AI models (Gemma, DeepSeek, LLaMA, Mistral, etc.).
- ğŸ’¸ **No Subscription Fees** â€“ No API keys, no usage limits, no paywalls.
- âš¡ **Fast & Offline** â€“ Works even without internet after setup.

---

## ğŸ–¥ Tested Environment

- **OS:** Arch Linux (should work on other Linux distros with Ollama installed)
- **Node.js:** v20+
- **MongoDB:** Local instance (v6+)
- **Ollama:** Latest version

---

## ğŸ¤– Required Ollama Models

This project supports multiple models and lets you **switch between them in the UI**.  
Youâ€™ll need to have them downloaded locally before running the app.

**Install models:**

```bash
ollama pull gemma3n:e2b
ollama pull gemma3:4b
ollama pull deepseek-r1:7b
ollama pull llava:latest
```

## âœ¨ Features

- ğŸ” User Authentication (NextAuth + Email/Password).
- ğŸ’¬ Clean Chat UI (mobile-friendly, ChatGPT-like).
- ğŸ”„ Switch between Ollama models (Gemma, DeepSeek, etc.).
- ğŸ’¬ image recoganisation .
- ğŸ“œ Chat History Sidebar (rename & delete chats).
- â³ Streaming / Typing Effect.
- ğŸ—„ Local MongoDB storage (no cloud required).
- ğŸŒ™ Dark mode support.
- âš¡ Runs entirely on your machine â€“ your data stays private.

## ğŸš€ Tech Stack

- Frontend: Next.js (App Router) + Tailwind CSS.
- Backend: Node.js API routes.
- Database: MongoDB (local).
- Auth: NextAuth.js.
- AI Engine: Ollama (local LLM runner).

---

## ğŸ“¦ Installation

1ï¸âƒ£ Install Dependencies

```bash
npm install
```

2ï¸âƒ£ Install & Start Ollama
Follow [Ollama install instructions] (https://ollama.com/download) for Linux.
Check models:

```bash
sudo systemctl start ollama
```

3ï¸âƒ£Run

```bash
npm run dev
```
